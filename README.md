## What are Transformers
- Specific type of neural network (NN).
- Consists of input, hidden, and output layers.
- Scales well with data, working with sequential data of any type.
- Examples: GPT for text, ViT for images, Whisper for audio.


## How They Work
- Transformers consist of encoders (contextual understanding) and decoders (text generation).
- Use embeddings and self-attention to process input sequences.

## Types of Transformers
- Auto-regressive (GPT): Decoder only, for text generation.
- Auto-Encoding (BERT): Encoder only, for understanding tasks.
- Sequence-to-Sequence (BART/T5): Both encoder and decoder, for translation and summarization.
